<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Model Reference - Vecto Pilot‚Ñ¢</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #1a1a1a;
            background: #ffffff;
            padding: 40px 20px;
            max-width: 1200px;
            margin: 0 auto;
        }
        h1 { 
            color: #0066cc;
            font-size: 2.5em;
            margin: 30px 0 20px 0;
            padding-bottom: 10px;
            border-bottom: 3px solid #0066cc;
        }
        h2 {
            color: #0077dd;
            font-size: 1.8em;
            margin: 25px 0 15px 0;
            padding-bottom: 8px;
            border-bottom: 2px solid #e0e0e0;
        }
        h3 {
            color: #333;
            font-size: 1.4em;
            margin: 20px 0 10px 0;
        }
        h4 {
            color: #555;
            font-size: 1.1em;
            margin: 15px 0 8px 0;
        }
        p { margin: 12px 0; }
        code {
            background: #f5f5f5;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
            color: #d63384;
        }
        pre {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-left: 4px solid #0066cc;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9em;
            line-height: 1.4;
        }
        pre code {
            background: none;
            padding: 0;
            color: #212529;
        }
        ul, ol {
            margin: 12px 0 12px 30px;
        }
        li { margin: 6px 0; }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
        }
        th, td {
            border: 1px solid #dee2e6;
            padding: 12px;
            text-align: left;
        }
        th {
            background: #0066cc;
            color: white;
            font-weight: 600;
        }
        tr:nth-child(even) {
            background: #f8f9fa;
        }
        blockquote {
            border-left: 4px solid #ffc107;
            background: #fff3cd;
            padding: 15px 20px;
            margin: 15px 0;
            color: #856404;
        }
        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 15px 0;
        }
        .success {
            background: #d1e7dd;
            border-left: 4px solid #198754;
            padding: 15px;
            margin: 15px 0;
        }
        @media print {
            body { padding: 20px; }
            h1, h2, h3 { page-break-after: avoid; }
            pre, table { page-break-inside: avoid; }
        }
    </style>
</head>
<body>
<h1>AI Model Reference - Production Configuration</h1>
<p>**Last Updated**: October 8, 2025  </p>
<p>**Research Source**: Perplexity AI via <code>tools/research/model-discovery.mjs</code></p>

<hr>

<h2>üéØ Verified Production Models</h2>

<h3>OpenAI GPT-5 Pro</h3>
<p>**Status**: ‚úÖ Production (October 2025)</p>

<pre><code>
<p>OPENAI_MODEL=gpt-5-pro</p>
<pre><code>

<p>**API Details**:</p>
<li>**Endpoint**: <code>POST https://api.openai.com/v1/chat/completions</code></li>
<li>**Model ID**: <code>gpt-5-pro</code> (flagship reasoning model)</li>
<li>**Context Window**: 256K tokens (256,000 tokens/request)</li>
<li>**Headers**:</li>
<p>  - <code>Authorization: Bearer &lt;API_KEY&gt;</code></p>
<p>  - <code>Content-Type: application/json</code></p>

<p>**Supported Parameters** (‚ö†Ô∏è BREAKING CHANGES):</p>
<pre><code>
<p>{</p>
<p>  "model": "gpt-5-pro",</p>
<p>  "messages": [...],</p>
<p>  "reasoning_effort": "minimal" | "low" | "medium" | "high",  // ‚úÖ USE THIS</p>
<p>  "max_completion_tokens": 32000,</p>
<p>  "stream": true,</p>
<p>  "stop": [...],</p>
<p>  "tools": [...]  // For function calling</p>
<p>}</p>
<pre><code>

<p>**‚ùå DEPRECATED PARAMETERS** (GPT-5 does NOT support):</p>
<li><code>temperature</code> ‚Üí Use <code>reasoning_effort</code> instead</li>
<li><code>top_p</code> ‚Üí Use <code>reasoning_effort</code> instead</li>
<li><code>frequency_penalty</code> ‚Üí Not supported</li>
<li><code>presence_penalty</code> ‚Üí Not supported</li>

<p>**Token Usage** (special for GPT-5):</p>
<li>Input tokens: Standard</li>
<li>Reasoning tokens: Internal chain-of-thought (counted separately)</li>
<li>Output tokens: Final response</li>

<hr>

<h3>Anthropic Claude Sonnet 4.5</h3>
<p>**Status**: ‚úÖ Verified Working (October 8, 2025)</p>

<pre><code>
<p>CLAUDE_MODEL=claude-sonnet-4-5-20250929</p>
<p>ANTHROPIC_API_VERSION=2023-06-01</p>
<pre><code>

<p>**API Details**:</p>
<li>**Endpoint**: <code>POST https://api.anthropic.com/v1/messages</code></li>
<li>**Model ID**: <code>claude-sonnet-4-5-20250929</code></li>
<li>**Context Window**: 200K tokens (200,000 tokens standard, 1M with beta header)</li>
<li>**Headers**:</li>
<p>  - <code>x-api-key: &lt;API_KEY&gt;</code></p>
<p>  - <code>anthropic-version: 2023-06-01</code> (or <code>2025-10-01</code> for latest)</p>
<p>  - <code>Content-Type: application/json</code></p>

<p>**Supported Parameters**:</p>
<pre><code>
<p>{</p>
<p>  "model": "claude-sonnet-4-5-20250929",</p>
<p>  "messages": [...],</p>
<p>  "max_tokens": 64000,</p>
<p>  "temperature": 0.7,     // ‚úÖ Standard parameter</p>
<p>  "top_p": 0.95,          // ‚úÖ Supported</p>
<p>  "system": "...",        // ‚úÖ System prompt</p>
<p>  "stop_sequences": [...] // ‚úÖ Supported</p>
<p>}</p>
<pre><code>

<p>**‚úÖ VERIFICATION COMPLETE** (October 8, 2025):</p>
<pre><code>
<h1>Models API confirms availability</h1>
<p>curl https://api.anthropic.com/v1/models/claude-sonnet-4-5-20250929</p>
<h1>Response: {"type":"model","id":"claude-sonnet-4-5-20250929","display_name":"Claude Sonnet 4.5"}</h1>

<h1>Messages API returns correct model</h1>
<p>curl https://api.anthropic.com/v1/messages -d '{"model":"claude-sonnet-4-5-20250929",...}'</p>
<h1>Response: {"model":"claude-sonnet-4-5-20250929",...}</h1>
<pre><code>

<p>**Model Assertion**: Adapter includes validation to prevent silent model swaps  </p>
<p>**Pricing**:</p>
<li>Input: $8.00 per million tokens</li>
<li>Output: $24.00 per million tokens</li>

<p>**‚ö†Ô∏è Partner Platform ID Differences** (do NOT use with native Anthropic API):</p>
<li>**Vertex AI**: <code>claude-sonnet-4-5@20250929</code> (different format)</li>
<li>**AWS Bedrock**: <code>anthropic.claude-sonnet-4-5-20250929-v1:0</code> (global prefix)</li>
<li>**Native Anthropic**: <code>claude-sonnet-4-5-20250929</code> ‚úÖ Use this</li>

<hr>

<h3>Google Gemini 2.5 Pro</h3>
<p>**Status**: ‚úÖ Production (October 2025)</p>

<pre><code>
<p>GEMINI_MODEL=gemini-2.5-pro-latest</p>
<pre><code>

<p>**API Details**:</p>
<li>**Endpoint**: <code>POST https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent</code></li>
<li>**Model ID**: <code>gemini-2.5-pro-latest</code> (or <code>gemini-2.5-flash-latest</code> for speed)</li>
<li>**Context Window**: 1M tokens (1,000,000 tokens)</li>
<li>**Headers**:</li>
<p>  - <code>Authorization: Bearer &lt;API_KEY&gt;</code></p>
<p>  - <code>Content-Type: application/json</code></p>

<p>**Supported Parameters**:</p>
<pre><code>
<p>{</p>
<p>  "model": "gemini-2.5-pro-latest",</p>
<p>  "contents": [...],          // Gemini uses "contents" not "messages"</p>
<p>  "generationConfig": {</p>
<p>    "temperature": 0.7,       // ‚úÖ Standard 0.0-2.0</p>
<p>    "topP": 0.95,             // ‚úÖ Supported</p>
<p>    "maxOutputTokens": 2048,  // ‚úÖ Token limit</p>
<p>    "stopSequences": [...]    // ‚úÖ Supported</p>
<p>  }</p>
<p>}</p>
<pre><code>

<p>**Model Variants**:</p>
<li><code>gemini-2.5-pro-latest</code>: General-purpose reasoning</li>
<li><code>gemini-2.5-flash-latest</code>: High-speed, lower latency</li>
<li><code>gemini-2.5-computer-use-latest</code>: UI/agent control (preview)</li>

<hr>

<h2>üîÑ Model Deprecations (2024-2025)</h2>

<h3>OpenAI Deprecated Models</h3>

<p>| Deprecated Model | Sunset Date | Replacement |</p>
<p>|-----------------|-------------|-------------|</p>
<p>| <code>gpt-4-32k</code> | 2025-06-06 | <code>gpt-5-pro</code> |</p>
<p>| <code>gpt-4-vision-preview</code> | 2024-12-06 | <code>gpt-5-pro</code> |</p>
<p>| <code>gpt-4.5-preview</code> | 2025-07-14 | <code>gpt-5-pro</code> |</p>
<p>| <code>o1-preview</code> | 2025-07-28 | <code>o3</code> |</p>
<p>| <code>o1-mini</code> | 2025-10-27 | <code>o4-mini</code> |</p>
<p>| <code>codex</code> (standalone) | 2024-2025 | <code>gpt-5-pro</code> |</p>

<h3>Google Deprecated Models</h3>

<p>| Deprecated Model | Replacement |</p>
<p>|-----------------|-------------|</p>
<p>| <code>gemini-1.5-pro</code> | <code>gemini-2.5-pro-latest</code> |</p>
<p>| <code>gemini-1.5-flash</code> | <code>gemini-2.5-flash-latest</code> |</p>

<h3>Anthropic</h3>
<li>No official deprecations as of October 2025</li>
<li>Claude 2.x models being phased out in favor of Claude 3+ family</li>

<hr>

<h2>üìä Vecto Pilot‚Ñ¢ Configuration</h2>

<h3>Current Production Stack</h3>

<p>**Triad Pipeline** (Single-Path, No Fallbacks):</p>
<pre><code>
<h1>Triad Architecture</h1>
<p>TRIAD_ENABLED=true</p>
<p>TRIAD_MODE=single_path</p>

<h1>Stage 1: Strategist (Claude Sonnet 4.5)</h1>
<p>CLAUDE_MODEL=claude-sonnet-4-5-20250929</p>
<p>CLAUDE_TIMEOUT_MS=12000</p>

<h1>Stage 2: Planner (GPT-5 Pro)</h1>
<p>OPENAI_MODEL=gpt-5-pro</p>
<p>GPT5_TIMEOUT_MS=45000</p>
<p>GPT5_REASONING_EFFORT=high</p>

<h1>Stage 3: Validator (Gemini 2.5 Pro)</h1>
<p>GEMINI_MODEL=gemini-2.5-pro-latest</p>
<p>GEMINI_TIMEOUT_MS=15000</p>

<h1>Total Budget</h1>
<p>LLM_TOTAL_BUDGET_MS=90000</p>
<pre><code>

<p>**Agent Override (Atlas)** with Fallback Chain:</p>
<pre><code>
<h1>Primary: Atlas (Claude Sonnet 4.5)</h1>
<p>AGENT_OVERRIDE_PROVIDER=anthropic</p>
<p>AGENT_OVERRIDE_MODEL=claude-sonnet-4-5-20250929</p>

<h1>Fallback Chain: Claude ‚Üí GPT-5 ‚Üí Gemini</h1>
<h1>(Separate API keys from Triad)</h1>
<pre><code>

<h3>Router V2 (Currently Disabled)</h3>

<p>If re-enabling Router V2:</p>
<pre><code>
<p>ROUTER_V2_ENABLED=true</p>
<p>PREFERRED_MODEL=google:gemini-2.5-pro-latest</p>
<p>FALLBACK_MODELS=openai:gpt-5-pro,anthropic:claude-sonnet-4-5-20250929</p>

<h1>Router Timing</h1>
<p>LLM_PRIMARY_TIMEOUT_MS=1200</p>
<p>LLM_TOTAL_BUDGET_MS=20000</p>
<p>FALLBACK_HEDGE_STAGGER_MS=400</p>
<pre><code>

<hr>

<h2>üîß Implementation Notes</h2>

<h3>GPT-5 Pro Migration</h3>
<p>**Old (GPT-4)**:</p>
<pre><code>
<p>{</p>
<p>  model: "gpt-4",</p>
<p>  temperature: 0.7,  // ‚ùå Not supported in GPT-5</p>
<p>  top_p: 0.95        // ‚ùå Not supported in GPT-5</p>
<p>}</p>
<pre><code>

<p>**New (GPT-5)**:</p>
<pre><code>
<p>{</p>
<p>  model: "gpt-5-pro",</p>
<p>  reasoning_effort: "high",  // ‚úÖ Replaces temperature/top_p</p>
<p>  max_completion_tokens: 32000</p>
<p>}</p>
<pre><code>

<h3>Anthropic API Version</h3>
<li>Current: <code>anthropic-version: 2023-06-01</code></li>
<li>Latest: <code>anthropic-version: 2025-10-01</code></li>
<li>Both work with Sonnet 4.5</li>

<h3>Gemini Content Structure</h3>
<p>Gemini uses different JSON structure:</p>
<pre><code>
<p>// Gemini format:</p>
<p>{</p>
<p>  "contents": [</p>
<p>    { "role": "user", "parts": [{ "text": "..." }] }</p>
<p>  ]</p>
<p>}</p>

<p>// vs OpenAI/Anthropic format:</p>
<p>{</p>
<p>  "messages": [</p>
<p>    { "role": "user", "content": "..." }</p>
<p>  ]</p>
<p>}</p>
<pre><code>

<hr>

<h2>üß™ Testing &amp; Verification</h2>

<h3>Curl Examples (Using .env Parameters)</h3>

<h4>Test Claude Sonnet 4.5</h4>
<pre><code>
<h1>Using exact .env configuration</h1>
<p>curl -X POST "https://api.anthropic.com/v1/messages" \</p>
<p>  -H "x-api-key: $ANTHROPIC_API_KEY" \</p>
<p>  -H "anthropic-version: 2023-06-01" \</p>
<p>  -H "Content-Type: application/json" \</p>
<p>  -d '{</p>
<p>    "model": "claude-sonnet-4-5-20250929",</p>
<p>    "max_tokens": 30000,</p>
<p>    "messages": [</p>
<p>      {</p>
<p>        "role": "user",</p>
<p>        "content": "Respond with only: CLAUDE SONNET 4.5 VERIFIED"</p>
<p>      }</p>
<p>    ]</p>
<p>  }'</p>

<h1>Expected response:</h1>
<h1>{"id":"msg_...","model":"claude-sonnet-4-5-20250929",...,"content":[{"text":"CLAUDE SONNET 4.5 VERIFIED"}]}</h1>
<pre><code>

<h4>Test OpenAI GPT-5</h4>
<pre><code>
<h1>Using exact .env configuration (reasoning_effort: medium)</h1>
<p>curl -X POST "https://api.openai.com/v1/chat/completions" \</p>
<p>  -H "Authorization: Bearer $OPENAI_API_KEY" \</p>
<p>  -H "Content-Type: application/json" \</p>
<p>  -d '{</p>
<p>    "model": "gpt-5",</p>
<p>    "messages": [</p>
<p>      {</p>
<p>        "role": "user",</p>
<p>        "content": "Respond with only: GPT-5 VERIFIED"</p>
<p>      }</p>
<p>    ],</p>
<p>    "reasoning_effort": "medium",</p>
<p>    "max_completion_tokens": 32000</p>
<p>  }'</p>

<h1>Expected response:</h1>
<h1>{"id":"chatcmpl-...","model":"gpt-5",...,"choices":[{"message":{"content":"GPT-5 VERIFIED"}}]}</h1>
<pre><code>

<h4>Test Google Gemini 2.5 Pro</h4>
<pre><code>
<h1>Using exact .env configuration (temperature: 0.2)</h1>
<p>curl -X POST "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key=$GOOGLEAQ_API_KEY" \</p>
<p>  -H "Content-Type: application/json" \</p>
<p>  -d '{</p>
<p>    "contents": [</p>
<p>      {</p>
<p>        "parts": [</p>
<p>          {</p>
<p>            "text": "Respond with only: GEMINI 2.5 PRO VERIFIED"</p>
<p>          }</p>
<p>        ]</p>
<p>      }</p>
<p>    ],</p>
<p>    "generationConfig": {</p>
<p>      "temperature": 0.2,</p>
<p>      "maxOutputTokens": 2048</p>
<p>    }</p>
<p>  }'</p>

<h1>Expected response:</h1>
<h1>{"candidates":[{"content":{"parts":[{"text":"GEMINI 2.5 PRO VERIFIED"}]}}]}</h1>
<pre><code>

<h3>Quick Node.js Tests</h3>

<p>**Test Anthropic**:</p>
<pre><code>
<p>node -e "fetch('https://api.anthropic.com/v1/messages',{method:'POST',headers:{'content-type':'application/json','anthropic-version':'2023-06-01','x-api-key':process.env.ANTHROPIC_API_KEY},body:JSON.stringify({model:'claude-sonnet-4-5-20250929',max_tokens:64,messages:[{role:'user',content:'ping'}]})}).then(r=&gt;r.json()).then(console.log)"</p>
<pre><code>

<p>**Test OpenAI GPT-5**:</p>
<pre><code>
<p>node -e "fetch('https://api.openai.com/v1/chat/completions',{method:'POST',headers:{'authorization':'Bearer '+process.env.OPENAI_API_KEY,'content-type':'application/json'},body:JSON.stringify({model:'gpt-5',messages:[{role:'user',content:'ping'}],reasoning_effort:'medium',max_completion_tokens:64})}).then(r=&gt;r.json()).then(console.log)"</p>
<pre><code>

<p>**Test Gemini**:</p>
<pre><code>
<p>curl -X POST "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key=$GOOGLEAQ_API_KEY" \</p>
<p>  -H 'Content-Type: application/json' \</p>
<p>  -d '{"contents":[{"parts":[{"text":"ping"}]}]}'</p>
<pre><code>

<h3>Automated Research</h3>
<pre><code>
<h1>Update this document with latest model info</h1>
<p>node tools/research/model-discovery.mjs</p>

<h1>Review generated report</h1>
<p>cat tools/research/model-research-$(date +%Y-%m-%d).json</p>
<pre><code>

<hr>

<h2>üìö Research Citations</h2>

<p>Full research report with citations available at:</p>
<li><code>tools/research/model-research-2025-10-08.json</code></li>

<p>Key sources:</p>
<li>OpenAI Platform Docs: https://platform.openai.com/docs</li>
<li>Anthropic Docs: https://www.anthropic.com/news/claude-sonnet-4-5</li>
<li>Google AI Docs: https://ai.google.dev/gemini-api/docs/models</li>
<li>Research Engine: Perplexity AI (sonar-pro)</li>

<hr>

<h2>üîÑ Update Workflow</h2>

<p>1. **Run Research Script**: <code>node tools/research/model-discovery.mjs</code></p>
<p>2. **Review JSON Report**: Check <code>tools/research/model-research-YYYY-MM-DD.json</code></p>
<p>3. **Update This File**: Sync MODEL.md with findings</p>
<p>4. **Update Adapters**: Modify <code>server/lib/adapters/*.js</code> files</p>
<p>5. **Update .env**: Set new model IDs and parameters</p>
<p>6. **Test Endpoints**: Verify each model via curl/node tests</p>
<p>7. **Update README**: Ensure README.md references current models</p>

<hr>

<p>*This document is automatically generated from Perplexity AI research. For manual updates, edit this file and document changes in git commit messages.*</p>
</body>
</html>
