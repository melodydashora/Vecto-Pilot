{
  "generated_at": "2025-12-01T15:50:40.699Z",
  "research_date": "December 1, 2025",
  "providers": [
    {
      "provider": "OpenAI",
      "timestamp": "2025-12-01T15:50:23.642Z",
      "answer": "I appreciate your detailed request, but I need to be transparent about the limitations of the available information. The search results provided do not contain the specific technical details you're requesting about OpenAI's production API models as of December 2025.\n\n## What the Search Results Confirm\n\nThe search results confirm that OpenAI has released **GPT-5.1** as of November 2025, with two variants:[4]\n\n- **GPT-5.1 Instant** - positioned as the warmer, more instruction-following default replacement for GPT-5\n- **GPT-5.1 Thinking** - a more capable variant with adaptive reasoning that adjusts computational effort based on task complexity\n\nThe search results also mention that **o1-pro** is available through the developer API with specific pricing of $150 per million input tokens and $600 per million output tokens.[3]\n\n## Information Not Available in Search Results\n\nThe search results do not provide:\n\n- Exact model ID strings for API calls (e.g., whether it's `gpt-5.1-instant` or another format)\n- Official API endpoint URLs\n- Required HTTP headers for authentication\n- Complete parameter specifications (whether GPT-5.1 uses `reasoning_effort` vs. `temperature`)\n- Context window sizes for each model variant\n- Current pricing for GPT-5.1 models\n- SDK package names and versions\n- Detailed feature constraints or rate limits\n\n## Regarding Your Verification List\n\nI cannot verify the model IDs you provided (`gpt-5`, `claude-sonnet-4-5-20250929`, `gemini-2.5-pro`) as production models because:\n\n1. The search results reference **GPT-5.1** (not `gpt-5`) as the current production model\n2. No information about Anthropic's Claude Sonnet 4.5 appears in these results\n3. The results mention **Gemini 3** (not `gemini-2.5-pro`) as Google's latest frontier model\n\n**To obtain accurate, current API documentation**, you should consult OpenAI's official API documentation at their developer platform, which would contain exact model IDs, endpoint URLs, authentication headers, parameter specifications, and current pricing.",
      "citations": [
        "https://nathanbenaich.substack.com/p/state-of-ai-december-2025-newsletter",
        "https://www.aiacceleratorinstitute.com/case-study-openai/",
        "https://techcrunch.com/2025/11/26/chatgpt-everything-to-know-about-the-ai-chatbot/",
        "https://siliconangle.com/2025/11/12/openais-gpt-5-1-model-gets-personality-makeover-superior-reasoning-skills/",
        "https://leonfurze.com/2025/11/26/the-near-future-of-genai-december-2025-update-part-1/",
        "https://openai.com/news/",
        "https://www.nasdaq.com/articles/accenture-openai-collaborate-launch-flagship-ai-platform-core-business",
        "https://openai.com/index/mixpanel-incident/"
      ],
      "relatedQuestions": []
    },
    {
      "provider": "Anthropic",
      "timestamp": "2025-12-01T15:50:24.733Z",
      "answer": "# Anthropic Production AI Models (December 2025)\n\nBased on the current information available, Anthropic has released several production models as of December 2025. However, I must note that the search results do not contain the specific technical details you've requested, such as exact API endpoint URLs, HTTP headers, parameter specifications, and SDK package names. I can provide the models that are confirmed in production, but cannot verify all the technical specifications you've listed.\n\n## Current Production Models\n\n**Claude Opus 4.5** is Anthropic's flagship model as of December 2025[1][4]. This is the most recently released model in Anthropic's 4.5 series and represents their most capable offering for production deployment.\n\n**Claude Sonnet 4.5** was released on September 29, 2025[1], and remains available for production use. This model is positioned for coding, agents, and computer use tasks.\n\n**Claude Haiku 4.5** was released on October 15, 2025[1], and is optimized for low latency and cost-sensitive applications.\n\n## Model Specifications\n\n| Model | Release Date | Context Window | Input Pricing | Output Pricing | Primary Use Case |\n|-------|--------------|-----------------|----------------|-----------------|------------------|\n| Claude Opus 4.5 | November 2025 | Not specified in results | Not specified | Not specified | General-purpose, coding, agents |\n| Claude Sonnet 4.5 | September 29, 2025 | 200,000 tokens | $3/M tokens | $15/M tokens | Coding, agents, computer use |\n| Claude Haiku 4.5 | October 15, 2025 | Not specified | $1/M tokens | $5/M tokens | Real-time assistants, customer support |\n\n## Performance Highlights\n\nClaude Opus 4.5 achieved over 80% on SWE-Bench Verified, making it the first model to surpass this threshold on this coding benchmark[4]. Claude Sonnet 4.5 reported 77.2% on SWE-Bench Verified with standard configuration and 82.0% under high-compute settings[1].\n\n## Available Features\n\nAnthropic's production models support several advanced features[1]:\n- Computer use (interpreting screen content and simulating input)\n- Web search (for Claude Max users in the US)\n- Code execution tools\n- Model Context Protocol (MCP) connector\n- Files API\n- Chrome extension integration (Claude for Chrome)\n- Excel integration (Claude for Excel)\n\n## Limitations of Available Information\n\nThe search results do not contain the specific technical implementation details you requested, including:\n- Exact model IDs for API calls (the personalization mentioned `claude-sonnet-4-5-20250929`, but this is not confirmed in the search results)\n- API endpoint URLs\n- Required HTTP headers\n- Detailed parameter specifications (temperature, top_p, max_tokens, etc.)\n- SDK package names and versions\n\nTo obtain this production-level technical documentation, you would need to consult Anthropic's official API documentation directly, which is not included in these search results.",
      "citations": [
        "https://en.wikipedia.org/wiki/Claude_(language_model)",
        "https://overchat.ai/ai-hub/claude-opus-4-5",
        "https://www.anthropic.com/research",
        "https://techcrunch.com/2025/11/24/anthropic-releases-opus-4-5-with-new-chrome-and-excel-integrations/"
      ],
      "relatedQuestions": []
    },
    {
      "provider": "Google AI (Gemini)",
      "timestamp": "2025-12-01T15:50:24.353Z",
      "answer": "# Google Gemini Production Models (December 2025)\n\nBased on current information, Google's production-ready Gemini models have evolved significantly. Here's what's available for production use:\n\n## Current Production Models\n\n**Gemini 3 Pro** (`gemini-3-pro-preview`) is Google's latest flagship model, released on November 18, 2025.[1][2] This represents the state-of-the-art reasoning and multimodal understanding model with powerful agentic and coding capabilities.[2] However, note that this is still in preview status despite being production-available.\n\n**Gemini 2.5 Pro** (`gemini-2.5-pro`) remains available as a stable, production-ready model released on June 17, 2025.[2] This model includes adaptive thinking capabilities and maintains a 1 million token context window.[1]\n\n**Gemini 2.5 Flash** is the default faster model for lower-latency applications, optimized for speed while maintaining strong performance.[1]\n\n## Important Clarification on Your Verification Request\n\nYour query mentions `gemini-2.5-pro` as a known flagship model to verify. However, the search results do not contain the specific technical details you requested:\n\n- **API endpoint URLs** - Not provided in available documentation\n- **Required HTTP headers** - Not specified in search results\n- **Supported parameters** (temperature, max_tokens, etc.) - Not detailed\n- **Pricing per million tokens** - Not included in search results\n- **SDK package names** - Not mentioned\n\n## What the Search Results Confirm\n\nThe search results confirm that Gemini 3 Pro outperformed major AI models in 19 out of 20 benchmarks tested, including surpassing OpenAI's GPT-5 Pro in Humanity's Last Exam (41% accuracy vs. 31.64%).[1] Both Gemini 2.5 Pro and Flash support native audio output and improved security features.[1]\n\n## Recommendation\n\nTo obtain the complete technical specifications you need (exact API endpoints, parameter names, pricing, and SDK details), you should consult the official Google AI for Developers documentation at `ai.google.dev`, which maintains current API reference materials. The search results provided focus on model capabilities and release information rather than implementation details required for production API integration.",
      "citations": [
        "https://en.wikipedia.org/wiki/Gemini_(language_model)",
        "https://ai.google.dev/gemini-api/docs/changelog",
        "https://gemini.google/ca/release-notes/?hl=en-CA",
        "https://techcrunch.com/2025/11/18/google-launches-gemini-3-with-new-coding-app-and-record-benchmark-scores/",
        "https://fortune.com/2025/11/18/google-releases-gemini-3-ai-model-search-ai-overviews/",
        "https://blog.adobe.com/en/publish/2025/11/20/google-gemini-3-nano-banana-pro-firefly-photoshop",
        "https://vertu.com/lifestyle/top-8-ai-models-ranked-gemini-3-chatgpt-5-1-grok-4-claude-4-5-more/"
      ],
      "relatedQuestions": []
    },
    {
      "provider": "Perplexity AI",
      "timestamp": "2025-12-01T15:50:21.090Z",
      "answer": "I don't have access to detailed technical specifications for Perplexity AI's production models as of December 2025. The search results provided focus on Perplexity's business metrics, market position, and product features rather than API documentation.\n\n## What the Search Results Reveal\n\nThe available information indicates that Perplexity AI operates as an answer engine that leverages **multiple large language models**, including GPT-4, Claude, and Mistral, in addition to proprietary models[1]. However, the search results do not contain:\n\n- Specific model IDs or exact API endpoint URLs for Perplexity's own models\n- HTTP header requirements\n- Supported parameters (temperature, max_tokens, context windows)\n- Pricing information per million tokens\n- SDK package names\n- API documentation details\n\n## Why This Information Isn't Available\n\nPerplexity AI's public documentation and announcements focus on its consumer-facing answer engine capabilities rather than detailed API specifications. The company does offer Perplexity Pro with API access[1], but the search results don't include the technical API documentation needed to answer your query comprehensively.\n\n## Recommendation\n\nTo obtain accurate, current production API specifications for Perplexity AI, you would need to:\n\n1. Visit Perplexity's official API documentation portal directly\n2. Contact Perplexity's developer support team\n3. Check their GitHub repositories for SDK information\n4. Review their official pricing and model documentation pages\n\nThis will ensure you have the exact model IDs, endpoint URLs, parameter specifications, and pricing information required for production implementation.",
      "citations": [
        "https://entrepreneurloop.com/perplexity-ai-origin-story-founders-journey/",
        "https://opentools.ai/news/perplexity-ais-trillion-parameter-marvel-revolutionizing-aws-with-efa",
        "https://techcrunch.com/2025/11/25/openai-and-perplexity-are-launching-ai-shopping-assistants-but-competing-startups-arent-sweating-it/",
        "https://firstpagesage.com/reports/top-generative-ai-chatbots/",
        "https://leonfurze.com/2025/11/26/the-near-future-of-genai-december-2025-update-part-1/",
        "https://www.omnius.so/blog/ai-search-industry-report",
        "https://techcrunch.com/2025/11/20/perplexity-brings-its-ai-browser-comet-to-android/",
        "https://www.perplexity.ai/finance",
        "https://timesofindia.indiatimes.com/technology/tech-news/mark-cuban-to-perplexity-openai-anthropic-google-microsoft-you-are-overspending-on-ai-only-one-you-will-/articleshow/125591144.cms"
      ],
      "relatedQuestions": []
    },
    {
      "provider": "News & Events APIs",
      "timestamp": "2025-12-01T15:50:21.446Z",
      "answer": "I don't have access to current API documentation for the specific event discovery APIs you're asking about. The search results provided focus on Perplexity AI's general functionality, Google Calendar integrations, and how Perplexity works as a search engine—but they don't contain the technical API specifications, endpoint URLs, or parameter details needed to answer your query accurately.\n\nTo get the precise information you need as of December 2025, I recommend:\n\n**For Perplexity AI API**: Check the official Perplexity API documentation portal for current web search parameters, location filtering capabilities, and recency filter options.\n\n**For SerpAPI**: Review their API reference documentation for the `google_events` engine specifications, parameter names like `tbm` and `tbs`, and location-based filtering syntax.\n\n**For NewsAPI**: Consult their current API documentation for location/proximity filtering, available sort parameters, and hyperlocal search limitations.\n\n**For Google Gemini 2.5 Pro**: Access Google's official Gemini API documentation for structured data extraction, geocoding capabilities, and model configuration parameters.\n\nSince these APIs evolve frequently and you need exact parameter names, valid value ranges, and current endpoint URLs, consulting the official documentation directly will ensure you have the most accurate and up-to-date information for your hyperlocal event discovery implementation.",
      "citations": [
        "https://www.appypieautomate.ai/integrate/apps/google-calendar/integrations/perplexity-ai",
        "https://hostman.com/blog/how-perplexity-ai-works/",
        "https://gmbapi.com/product/local-llm-tracking-ai-search-visibility/",
        "https://www.perplexity.ai/help-center/en/articles/11521526-perplexity-tasks",
        "https://www.index.dev/blog/perplexity-vs-google-ai-overviews",
        "https://picovoice.ai/blog/add-voice-to-perplexity/"
      ],
      "relatedQuestions": []
    }
  ],
  "parameter_constraints": {
    "topic": "parameter_constraints",
    "timestamp": "2025-12-01T15:50:33.330Z",
    "answer": "## OpenAI GPT-5 Parameters\n\n**GPT-5 does not support temperature, top_p, frequency_penalty, or presence_penalty.**[2] These parameters are explicitly unsupported with reasoning models. Additionally, GPT-5 does not support logprobs, top_logprobs, logit_bias, or max_tokens.[2]\n\nInstead of these traditional sampling parameters, GPT-5 uses **reasoning_effort** to control model behavior. The valid values for reasoning_effort are: **minimal, low, medium, and high**.[2]\n\nThe reasoning_effort parameter replaces the granular control previously available through temperature and top_p sampling parameters. Rather than adjusting probability distributions, reasoning_effort controls the computational resources and reasoning depth the model applies to your request.\n\n### Breaking Changes from GPT-4 to GPT-5\n\nThe shift from GPT-4 to GPT-5 represents a significant architectural change. GPT-5 is a reasoning model with a fundamentally different parameter structure. Applications using standard chat completions parameters like temperature, top_p, frequency_penalty, and presence_penalty will need to be refactored to use reasoning_effort instead. This is a breaking change that requires code modifications for any existing GPT-4 integrations migrating to GPT-5.\n\n## Anthropic Claude Sonnet 4.5 Parameters\n\nThe search results do not contain specific information about which API parameters Claude Sonnet 4.5 supports. However, the model ID for Claude Sonnet 4.5 is **claude-sonnet-4-5-20250929**. To obtain the complete parameter documentation for Claude Sonnet 4.5, you would need to consult Anthropic's official API documentation.\n\n## Google Gemini 2.5 Pro Parameters\n\nGemini 2.5 Pro supports **standard temperature and max_tokens parameters**. The search results confirm these are currently supported in production, though specific valid ranges are not detailed in the provided information.",
    "citations": [
      "https://platform.openai.com/docs/deprecations",
      "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/reasoning?view=foundry-classic",
      "https://gptforwork.com/help/release-notes",
      "https://developers.openai.com/changelog/",
      "https://help.openai.com/zh-hant/articles/10128477-chatgpt-enterprise-edu-release-notes"
    ]
  },
  "deprecated_models": {
    "topic": "deprecated_models",
    "timestamp": "2025-12-01T15:50:40.699Z",
    "answer": "## OpenAI Model Deprecations\n\n**Recent Deprecations (Late 2024 - Early 2025)**\n\nOpenAI has deprecated several models during this period with specific shutdown dates:\n\n**gpt-4.5-preview** was deprecated on April 14th, 2025, with a shutdown date of July 14, 2025.[1] The recommended replacement is `gpt-4.1`.[1][3]\n\n**o1-preview** was deprecated on April 28th, 2025, with a shutdown date of July 28, 2025.[1] The recommended replacement is `o3`.[1][3]\n\n**o1-mini** was also deprecated on April 28th, 2025, with a shutdown date of October 27, 2025.[1] The recommended replacement is `o4-mini`.[1]\n\n**gpt-4o-realtime-preview-2024-10-01** was deprecated on June 10th, 2025, with a shutdown date of September 10, 2025.[1] The recommended replacement is `gpt-4o-realtime-preview`.[1]\n\n**gpt-4o-audio-preview-2024-10-01** was also deprecated on June 10th, 2025, with a shutdown date of September 10, 2025.[1] The recommended replacement is `gpt-4o-audio-preview`.[1]\n\n**Fine-tuning Restrictions**\n\nNew fine-tuning training on `babbage-002` and `davinci-002` was discontinued on October 28, 2024.[1] Both should be replaced with `gpt-4o-mini` for new fine-tuning work.[1] Note that fine-tuned models already created from these base models remain accessible.\n\n**Upcoming Deprecation**\n\nDALL·E model snapshots were notified of deprecation on November 14th, 2025, with a shutdown date of May 12, 2026.[4]\n\n## Information Limitations\n\nThe search results provided contain information only about OpenAI's deprecations. Specific confirmed deprecation information for Anthropic and Google AI models from official sources is not available in the provided search results. To obtain accurate deprecation timelines for those providers, you would need to consult their official documentation directly.",
    "citations": [
      "https://platform.openai.com/docs/deprecations",
      "https://netus.ai/blog/gpt-4-retired",
      "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/legacy-models?view=foundry-classic",
      "https://community.openai.com/t/openai-is-making-a-huge-mistake-by-deprecating-dall-e-3/1367228",
      "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/model-retirements?view=foundry-classic",
      "https://community.openai.com/t/deprecation-of-chat-gpt-4o-latest/1367091",
      "https://help.openai.com/en/articles/6825453-chatgpt-release-notes"
    ]
  },
  "recommendations": [
    {
      "priority": "HIGH",
      "item": "GPT-5 Parameter Update",
      "detail": "GPT-5 uses reasoning_effort instead of temperature. Update server/lib/adapters/openai-gpt5.js to remove unsupported parameters.",
      "snapshot_note": "OpenAI may return snapshot IDs like gpt-5-2025-08-07. Adapter should check model family (startsWith) not exact match."
    },
    {
      "priority": "HIGH",
      "item": "Model Deprecation",
      "detail": "Some models may be deprecated. Review the deprecated_models section and update your codebase."
    },
    {
      "priority": "MEDIUM",
      "item": "Claude 4.5 Verification",
      "detail": "Verify Claude Sonnet 4.5 model ID matches what you have in server/lib/adapters/anthropic-sonnet45.js"
    }
  ],
  "next_steps": [
    "Review all findings against official documentation",
    "Update server/lib/adapters/* files with new model names",
    "Update docs/reference/LLM_MODELS_REFERENCE.md",
    "Update .env.example with new model defaults",
    "Test each model with tools/testing endpoints",
    "Update ISSUES.md if deprecated models are still in use"
  ]
}